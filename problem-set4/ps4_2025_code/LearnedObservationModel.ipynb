{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBciS_TD3JVl"
      },
      "source": [
        "# CS231a PSET 4 Problem 3: Linear Kalman Filter with a Learned Inverse Observation Model\n",
        "\n",
        "Building on the idea of learning useful representations for downstream tasks we saw in the last problem, in this problem you will see how this can be done for the task of monocular depth estimation.\n",
        "\n",
        "**Using a GPU**. Make sure to first change your runtime to use a GPU: click Runtime -> Change runtime type -> Hardware Accelerator -> GPU and your Colab instance will automatically be backed by GPU compute.\n",
        "\n",
        "Note: there is a known issue of the RAM running out while loading the second set of data after training. To get around this, after training please just restart the runtime and rerun the first 3 cells (prior to loading the training data) followed by the cells under 'Using the model'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwQRvE4C3gf5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in your Drive where you have saved the data\n",
        "# folder from the pset folder\n",
        "# e.g. 'cs231a/ps4'\n",
        "FOLDERNAME = 'cs231a/ps4_code'\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cd $FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jJqDYf2__-HF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "import gc\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM_rDf34_xC5"
      },
      "source": [
        "# Loading the data for part (i)\n",
        "\n",
        "Let's start by loading our datasets into memory:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZS7hG29LQUR"
      },
      "outputs": [],
      "source": [
        "def load_dataset(root, split=\"train\"):\n",
        "    labels = np.load(root + 'Q3A_positions_'+split+'.npy')\n",
        "    num_images = labels.shape[0]\n",
        "    images = np.empty(shape=(num_images, 480, 640,3))\n",
        "    for i in tqdm(range(num_images), desc='Loading data'):\n",
        "        im = Image.open(root + 'img_%03d_%s.png'%(i,split))\n",
        "        images[i] = np.array(im)/255.0\n",
        "    return images, labels\n",
        "\n",
        "image_train, label_train = load_dataset('data/Q3A_data/training_set/', 'train')\n",
        "image_test, label_test = load_dataset('data/Q3A_data/testing_set/', 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5YXdgoFHIiI"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "fig, axs = plt.subplots(n)\n",
        "for i in range(n):\n",
        "    idx = i\n",
        "    img = image_train[idx]\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].set_title('Train image %d, label %s'%(idx,str(label_train[idx])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTffBCOz7qwz"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "Next, we can go ahead and train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ObservationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ObservationModel, self).__init__()\n",
        "        self.conv1_1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(32)\n",
        "        self.conv1_2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn1_2 = nn.BatchNorm2d(32)\n",
        "        self.conv2_1 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(64)\n",
        "        self.conv2_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn2_2 = nn.BatchNorm2d(64)\n",
        "        self.conv3_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(128)\n",
        "        self.conv3_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn3_2 = nn.BatchNorm2d(128)\n",
        "        self.conv3_3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 2, 64)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.bn_fc2 = nn.BatchNorm1d(64)\n",
        "        self.fc3 = nn.Linear(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2, padding=0)\n",
        "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2, padding=0)\n",
        "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
        "        x = self.conv3_3(x)\n",
        "        \n",
        "        N, C, H, W = x.shape\n",
        "        features = x.view(N, C, -1).permute(0, 2, 1).contiguous().view(-1, C)\n",
        "        softmax = F.softmax(features, dim=1)\n",
        "        softmax = softmax.view(N, H, W, C).permute(0, 3, 1, 2).unsqueeze(-1)\n",
        "        \n",
        "        posx, posy = torch.meshgrid(torch.linspace(-1., 1., H), torch.linspace(-1., 1., W), indexing='ij')\n",
        "        posx = posx.view(1, 1, H, W, 1).to(x.device)\n",
        "        posy = posy.view(1, 1, H, W, 1).to(x.device)\n",
        "        image_coords = torch.cat([posx, posy], dim=-1)\n",
        "        \n",
        "        feature_points = torch.sum(softmax * image_coords, dim=[2, 3])\n",
        "        feature_points = feature_points.view(N, C * 2)\n",
        "        \n",
        "        x = F.relu(self.bn_fc1(self.fc1(feature_points)))\n",
        "        x = F.relu(self.bn_fc2(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPqmXtp0NjkS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming make_model is a function that returns an instance of a PyTorch model\n",
        "model = ObservationModel()\n",
        "criterion = nn.MSELoss()\n",
        "learning_rate = 3e-4\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# If using an M2/M3 Macbook, uncomment the following line\n",
        "# device = torch.device(\"mps\")\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "image_train_tensor = torch.tensor(image_train, dtype=torch.float32, device=device).permute(0, 3, 1, 2)\n",
        "label_train_tensor = torch.tensor(label_train, dtype=torch.float32, device=device)\n",
        "image_test_tensor = torch.tensor(image_test, dtype=torch.float32, device=device).permute(0, 3, 1, 2)\n",
        "label_test_tensor = torch.tensor(label_test, dtype=torch.float32, device=device)\n",
        "\n",
        "# Create DataLoader for training and testing\n",
        "train_dataset = TensorDataset(image_train_tensor, label_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(image_test_tensor, label_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc='Training'):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_image_train, batch_label_train in train_loader:\n",
        "        batch_image_train, batch_label_train = batch_image_train, batch_label_train\n",
        "        optimizer.zero_grad()\n",
        "        predict = model(batch_image_train)\n",
        "        loss = criterion(predict, batch_label_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "    \n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_image_test, batch_label_test in test_loader:\n",
        "            batch_image_test, batch_label_test = batch_image_test, batch_label_test\n",
        "            predict = model(batch_image_test)\n",
        "            loss = criterion(predict, batch_label_test)\n",
        "            test_loss += loss.item()\n",
        "    test_losses.append(test_loss / len(test_loader))\n",
        "    \n",
        "    torch.save(model.state_dict(), 'trained_model.pth')\n",
        "    if epoch > 1:\n",
        "        clear_output()\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "        ax1.plot(train_losses)\n",
        "        ax2.plot(test_losses)\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Train Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Test Loss')\n",
        "        plt.show()\n",
        "\n",
        "print(\"Final training loss: \", train_losses[-1])\n",
        "print(\"Final testing loss: \", test_losses[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EukgNo2DaG-6"
      },
      "outputs": [],
      "source": [
        "# run if using Colab and want to save memory\n",
        "%xdel image_train\n",
        "%xdel image_test\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVPQ4E7oHfDf"
      },
      "source": [
        "# Using the Model\n",
        "\n",
        "Now, let's use the model to make predictions for our Kalman Filter. Note that you may have to restart the runtime if your RAM runs out; just run the things up to 'Loading the data for part A' and then skip to this section. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If loading the model from a .pth, uncomment the following lines:\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = ObservationModel()\n",
        "# state_dict = torch.load(\"trained_model.pth\", map_location=device)\n",
        "# model.load_state_dict(state_dict)\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-o6KI0XHuoZ"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    labels = np.load('./data/Q3B_data/Q3B_positions_gt.npy')\n",
        "    num_images = labels.shape[0]\n",
        "    images = np.empty(shape=(num_images, 480, 640,3))\n",
        "    for i in tqdm(range(num_images),desc=\"Loading data\"):\n",
        "        im = Image.open('./data/Q3B_data/img_%03d.png'%(i))\n",
        "        images[i] = np.array(im)/255.0\n",
        "    return images, labels\n",
        "\n",
        "image_infer, label_infer = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy7zUhtJRy2N"
      },
      "outputs": [],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "predictions_val = []\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    for img in image_infer:\n",
        "        img_tensor = torch.tensor(img, device=device, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).float()  # Convert image to tensor and adjust dimensions\n",
        "        pred_val = model(img_tensor)\n",
        "        predictions_val.append(pred_val.squeeze().cpu().numpy())\n",
        "predictions_val = np.array(predictions_val)\n",
        "print('Mean error: ' + str(np.mean(np.linalg.norm(label_infer - predictions_val, axis=1))))\n",
        "np.save('./data/Q3B_predictions.npy', predictions_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N0OrMUQiaO36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NameError: name 'image_infer' is not defined\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1051"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# run if using Colab or want to save local memory\n",
        "%xdel image_infer\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y4rFSMVvOBK_"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8bae3fdcc294684b85c3363a604a979",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading data:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m         images[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(im)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m images, labels\n\u001b[1;32m---> 10\u001b[0m image_infer, label_infer \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[5], line 7\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_images),desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m     im \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/Q3D_data/img_\u001b[39m\u001b[38;5;132;01m%03d\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(i))\n\u001b[1;32m----> 7\u001b[0m     images[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(im)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images, labels\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def load_dataset():\n",
        "    labels = np.load('./data/Q3D_data/Q3D_positions_gt.npy')\n",
        "    num_images = labels.shape[0]\n",
        "    images = np.empty(shape=(num_images, 480, 640,3))\n",
        "    for i in tqdm(range(num_images),desc=\"Loading data\"):\n",
        "        im = Image.open('./data/Q3D_data/img_%03d.png'%(i))\n",
        "        images[i] = np.array(im)/255.0\n",
        "    return images, labels\n",
        "\n",
        "image_infer, label_infer = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fK4Pz6lR06s"
      },
      "outputs": [],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "predictions_val = []\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    for img in image_infer:\n",
        "        img_tensor = torch.tensor(img).unsqueeze(0).permute(0, 3, 1, 2).float()  # Convert image to tensor and adjust dimensions\n",
        "        pred_val = model(img_tensor)\n",
        "        predictions_val.append(pred_val.squeeze().numpy())\n",
        "predictions_val = np.array(predictions_val)\n",
        "print('Mean error: ' + str(np.mean(np.linalg.norm(label_infer - predictions_val, axis=1))))\n",
        "np.save('./data/Q3D_predictions.npy', predictions_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b2iaKy1OJLu"
      },
      "source": [
        "# Finishing Problem 4\n",
        "Now that you have the predictions .npy files, you can use these along with the completed code in p4.py to generate the plots needed for the PDF report. Congratulations on finishing the last 231a PSET!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3b2iaKy1OJLu"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "231aproj",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
